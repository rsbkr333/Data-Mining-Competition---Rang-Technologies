{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25766 entries, 0 to 25765\n",
      "Columns: 257 entries, Cust_id to Active_Customer\n",
      "dtypes: float64(234), int64(17), object(6)\n",
      "memory usage: 50.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May 20 16:36:06 2016\n",
    "\n",
    "@author: Aditya\n",
    "\"\"\"\n",
    "\n",
    "#Rang Competition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#Loading the data\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "\n",
    "#training\n",
    "train.info()\n",
    "#Missing values in any cell\n",
    "train.isnull().values.ravel().sum()\n",
    "#rows with missing values\n",
    "train.shape[0] - train.dropna().shape[0]\n",
    "cols = train.columns\n",
    "#numeric columns\n",
    "num_cols = train._get_numeric_data().columns\n",
    "#non-numerical columns\n",
    "list(set(cols)-set(num_cols))\n",
    "#encoding the categorical variable\n",
    "cat_encoder = LabelEncoder()\n",
    "cat1_encoder = LabelEncoder()\n",
    "cat2_encoder = LabelEncoder()\n",
    "cat3_encoder = LabelEncoder()\n",
    "cat4_encoder = LabelEncoder()\n",
    "cat_encoder.fit(train[\"Trans24\"])\n",
    "cat1_encoder.fit(train[\"Trans25\"])\n",
    "cat2_encoder.fit(train[\"Trans26\"])\n",
    "cat3_encoder.fit(train[\"Trans27\"])\n",
    "cat4_encoder.fit(train[\"Cust_status\"])\n",
    "train[\"Trans24\"] = cat_encoder.transform(train[\"Trans24\"])\n",
    "train[\"Trans25\"] = cat1_encoder.transform(train[\"Trans25\"])\n",
    "train[\"Trans26\"] = cat2_encoder.transform(train[\"Trans26\"])\n",
    "train[\"Trans27\"] = cat3_encoder.transform(train[\"Trans27\"])\n",
    "train[\"Cust_status\"] = cat4_encoder.transform(train[\"Cust_status\"])\n",
    "cat_encoder = LabelEncoder()\n",
    "cat1_encoder = LabelEncoder()\n",
    "cat2_encoder = LabelEncoder()\n",
    "cat3_encoder = LabelEncoder()\n",
    "cat4_encoder = LabelEncoder()\n",
    "cat_encoder.fit(test[\"Trans24\"])\n",
    "cat1_encoder.fit(test[\"Trans25\"])\n",
    "cat2_encoder.fit(test[\"Trans26\"])\n",
    "cat3_encoder.fit(test[\"Trans27\"])\n",
    "cat4_encoder.fit(test[\"Cust_status\"])\n",
    "test[\"Trans24\"] = cat_encoder.transform(test[\"Trans24\"])\n",
    "test[\"Trans25\"] = cat1_encoder.transform(test[\"Trans25\"])\n",
    "test[\"Trans26\"] = cat2_encoder.transform(test[\"Trans26\"])\n",
    "test[\"Trans27\"] = cat3_encoder.transform(test[\"Trans27\"])\n",
    "test[\"Cust_status\"] = cat4_encoder.transform(test[\"Cust_status\"])\n",
    "#Fill missing values with mean in all columns \n",
    "train = train.where(pd.notnull(train), train.mean(), axis = \"columns\")\n",
    "test = test.where(pd.notnull(test), test.mean(), axis = \"columns\")\n",
    "#Splitting the training set\n",
    "train_train, validation = train_test_split(train, random_state = 30)\n",
    "#selecting required columns\n",
    "train_columns = list(train.columns[2:256].values)\n",
    "test_columns = list(test.columns[2:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3477           0.0368            5.34m\n",
      "         2           1.3186           0.0281            3.87m\n",
      "         3           1.2933           0.0221            3.17m\n",
      "         4           1.2760           0.0181            2.89m\n",
      "         5           1.2615           0.0137            2.64m\n",
      "         6           1.2487           0.0119            2.41m\n",
      "         7           1.2372           0.0086            2.24m\n",
      "         8           1.2301           0.0081            2.10m\n",
      "         9           1.2209           0.0052            2.01m\n",
      "        10           1.2171           0.0059            1.93m\n",
      "        20           1.1857           0.0004            1.53m\n",
      "        30           1.1703           0.0003            1.40m\n",
      "        40           1.1597          -0.0001            1.22m\n",
      "        50           1.1504           0.0000            1.08m\n",
      "        60           1.1385          -0.0010           58.24s\n",
      "        70           1.1334          -0.0010           52.45s\n",
      "        80           1.1293          -0.0005           47.55s\n",
      "        90           1.1248          -0.0007           42.74s\n",
      "       100           1.1174           0.0000           38.49s\n",
      "       200           1.0648          -0.0004            3.20s\n"
     ]
    }
   ],
   "source": [
    "#Basic logistic model\n",
    "Model = GradientBoostingClassifier(loss='deviance', learning_rate=0.135, n_estimators=210, \n",
    "                                   subsample=0.80, min_samples_split=2, min_samples_leaf=1, \n",
    "                                   min_weight_fraction_leaf=0.0, max_depth=3, init=None, \n",
    "                                   random_state=50, max_features=None, verbose=1, \n",
    "                                   max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "Model.fit(train_train[train_columns],train_train[\"Active_Customer\"])\n",
    "Model.predict(validation[train_columns])\n",
    "Model.score(validation[train_columns],validation[\"Active_Customer\"])\n",
    "Model.feature_importances_\n",
    "predict = Model.predict(test[test_columns])\n",
    "\n",
    "#writing to csv\n",
    "result = pd.DataFrame(predict, columns=([\"Active_Customer\"]), index = test[\"Cust_id\"])\n",
    "result.to_csv(\"submission_110.csv\")\n",
    "\n",
    "#Model = GradientBoostingClassifier(loss='deviance', learning_rate=0.05, n_estimators=800, \n",
    "#                                   subsample=1.0, min_samples_split=10, min_samples_leaf=10, \n",
    "#                                   min_weight_fraction_leaf=0.0, max_depth=5, init=None, \n",
    "#                                   random_state=None, max_features=\"auto\", verbose=0, \n",
    "#                                   max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "#Model.fit(train_train[train_columns],train_train[\"Active_Customer\"])\n",
    "#Model.predict(validation[train_columns])\n",
    "#Model.score(validation[train_columns],validation[\"Active_Customer\"])\n",
    "#Model.feature_importances_\n",
    "#predict = Model.predict(test[test_columns])\n",
    "#Model = GradientBoostingClassifier(loss='deviance', learning_rate=0.125, n_estimators=250, \n",
    "#                                  subsample=0.85, min_samples_split=2, min_samples_leaf=1, \n",
    "#                                  min_weight_fraction_leaf=0.0, max_depth=3, init=None, \n",
    "#                                  random_state=50, max_features=\"auto\", verbose=1, \n",
    "#                                  max_leaf_nodes=None, warm_start=True, presort=\"auto\")\n",
    "#Model.fit(train_train[train_columns],train_train[\"Active_Customer\"])\n",
    "#Model.predict(validation[train_columns])\n",
    "#Model.score(validation[train_columns],validation[\"Active_Customer\"])\n",
    "#Model.feature_importances_\n",
    "#predict = Model.predict(test[test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XGBoost model\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.135,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 20,\n",
    "    'nthread': -1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'seed': 50,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "Model = xgb.XGBClassifier()\n",
    "Model.set_params(**params)\n",
    "Model.fit(train_train[train_columns],train_train[\"Active_Customer\"])\n",
    "Model.predict(validation[train_columns])\n",
    "Model.score(validation[train_columns],validation[\"Active_Customer\"])\n",
    "#Model.feature_importances_\n",
    "predict = Model.predict(test[test_columns])\n",
    "\n",
    "#writing to csv\n",
    "result = pd.DataFrame(predict, columns=([\"Active_Customer\"]), index = test[\"Cust_id\"])\n",
    "result.to_csv(\"submission_113.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
